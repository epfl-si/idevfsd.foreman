foreman_topdir: /srv/foreman

foreman_postgres_image: postgres:12
foreman_postgres_socket_dir: "{{ foreman_topdir }}/postgres/run"
foreman_postgres_storage_dir: "{{ foreman_topdir }}/postgres/data"
foreman_postgres_initdb_sql_script: "{{ foreman_topdir }}/postgres/initdb.sql"

foreman_version: 2.3.2
foreman_tasks_version: 3.0.5  # 4.0.0 wants foreman_version = 2.4.0
foreman_discovery_version: 16.3

foreman_frontend_base_image: "quay.io/foreman/foreman:{{ foreman_version }}"
foreman_frontend_build_dir: "{{ foreman_topdir }}/frontend/build"
foreman_frontend_image: "epflidevfsd/foreman:{{ foreman_version }}"
foreman_frontend_container_name: "foreman-{{ inventory_environment }}"
foreman_frontend_config_dir: "{{ foreman_topdir }}/frontend/config"
foreman_frontend_mounts:
  - type: bind
    source: "{{ foreman_postgres_socket_dir }}"
    target: /run/postgres
  - type: bind
    source: "{{ foreman_frontend_config_dir }}/database.yml"
    target: /home/foreman/config/database.yml
  - type: bind
    source: "{{ foreman_frontend_config_dir }}/settings.yaml"
    target: /home/foreman/config/settings.yaml
  - type: bind
    source: "{{ foreman_frontend_config_dir }}/foreman_column_view.yaml"
    target: /home/foreman/config/settings.plugins.d/foreman_column_view.yaml
  - type: bind
    source: "{{ traefik_selfsigned_cert_path }}"
    target: "{{ foreman_frontend_selfsigned_cert_path }}"
foreman_frontend_selfsigned_cert_path: /etc/ssl/certs/traefik-selfsigned.pem

foreman_smartproxy_build_dir: "{{ foreman_topdir }}/smartproxy/build"
foreman_smartproxy_image: "epflidevfsd/foreman-smartproxy:{{ foreman_version }}"
foreman_smartproxy_container_name: "smartproxy-{{ inventory_environment }}"
foreman_smartproxy_name: "smart proxy in Docker"
foreman_smartproxy_config_dir: "{{ foreman_topdir }}/smartproxy/config"
foreman_smartproxy_secrets_dir: "{{ foreman_topdir }}/smartproxy/secrets"
# The basenames are dictated by the default values of the
# smart_proxy_remote_execution_ssh plugin:
foreman_smartproxy_ssh_private_key_path: "{{ foreman_smartproxy_secrets_dir }}/id_rsa_foreman_proxy"
foreman_smartproxy_ssh_public_key_path: "{{ foreman_smartproxy_ssh_private_key_path }}.pub"

foreman_docker_rails_interpreter:
  - docker
  - exec
  - "-i"
  - "{{ foreman_frontend_container_name }}"
  - bundle
  - exec
  - rails
  - console

foreman_keybase_credentials_file: /keybase/team/epfl_idevfsd/foreman/credentials.yml
_foreman_keybase_credentials: >-
  {{ lookup("file", foreman_keybase_credentials_file) | from_yaml }}
foreman_admin_user: "{{ _foreman_keybase_credentials.foreman_web_ui.login }}"
foreman_admin_password: "{{ _foreman_keybase_credentials.foreman_web_ui.password }}"

foreman_api_environment:
  FOREMAN_SERVER_URL: "{{ foreman_frontend_url }}"
  FOREMAN_USERNAME: "{{ foreman_admin_user }}"
  FOREMAN_PASSWORD: "{{ foreman_admin_password }}"
  FOREMAN_VALIDATE_CERTS: no

foreman_main_organization_name: IDEV-FSD
foreman_main_location_name: XaaS Prod

foreman_ptable_template_name: "IC-IT style preseed LVM partition table"

foreman_kexec_template_name: "EPFL Debian kexec"
foreman_kexec_template_name_adapted_from_url: >-
  https://raw.githubusercontent.com/theforeman/foreman_discovery/{{
    foreman_discovery_version }}-stable/app/views/foreman_discovery/debian_kexec.erb


foreman_default_install:
  architecture: "x86_64"
  operatingsystem: "Ubuntu 20.04"
  medium: "Ubuntu mirror"
  ptable: "{{ foreman_ptable_template_name }}"

foreman_hostgroup_params:
  organization: >-
    {{ hostgroup.organization
       | default(foreman_main_organization_name) }}
  locations: >-
    {{ hostgroup.location
       | default(foreman_main_location_name) }}
  domain: "{{ hostgroup.domain }}"
  subnet: "{{ hostgroup.subnet }}"
  architecture: >-
    {{ hostgroup.architecture
       | default(foreman_default_install.architecture) }}
  operatingsystem: >-
    {{ hostgroup.operatingsystem
       | default(foreman_default_install.operatingsystem) }}
  medium: >-
    {{ hostgroup.medium
       | default(foreman_default_install.medium) }}
  ptable: >-
    {{ hostgroup.ptable
       | default(foreman_default_install.ptable) }}
  dns_primary: >-
    {{ hostgroup.dns_primary | default("128.178.15.227") }}
  dns_secondary: >-
    {{ hostgroup.dns_secondary   if hostgroup.dns_secondary is defined
       else None                 if hostgroup.dns_primary is defined
       else "128.178.15.228" }}

# https://github.com/kubernetes-sigs/kubespray/blob/master/docs/vars.md
foreman_hostgroup_ansible_vars:
- name: kubespray_cluster_name
  type: string
  default_value: "{{ hostgroup_name }}"
- name: kubespray_dns_domain
  type: string
  default_value: "{{ hostgroup_name }}.local"
- name: kube_service_addresses
  type: string
  default_value: "172.30.0.0/16"   # Camptocamp-OpenShift-style
- name: kube_pods_subnet
  type: string
  default_value: "172.31.0.0/16"   # Ditto
- name: kube_network_node_prefix
  type: integer
  default_value: 23                # Leaving room for ~126 nodes running ~510 pods each
- name: kubespray_enable_dual_stack_networks
  type: boolean
  # If you want IPv6, then your nodes must have a true IPv6 address (not fe80::/32).
  default_value: false
- name: kube_pods_subnet_ipv6
  type: string
  # kubeadm doesn't believe in clusters with more than 65535 nodes (https://github.com/kubernetes/kubernetes/blob/master/cmd/kubeadm/app/constants/constants.go#L215):
  default_value: >-
    {{ hostgroup_name | ipv6_ula | replace("::/48", "::/80") }}
- name: kube_network_node_prefix_ipv6
  type: integer
  default_value: 96
  # Kubeadm also doesn't believe in zillions of services
  # (op. cit., https://github.com/kubernetes/kubernetes/blob/master/cmd/kubeadm/app/constants/constants.go#L206):
- name: kube_service_addresses_ipv6
  type: string
  default_value: >-
    {{ hostgroup_name | ipv6_ula | replace("::/48", ":0:0:1::/112") }}
